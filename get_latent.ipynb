{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import scanpy as sc\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "from torch.optim import lr_scheduler\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from umap.umap_ import UMAP\n",
    "# from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "from cuml import PCA, UMAP\n",
    "import cupy as cp\n",
    "\n",
    "from model_VAE import VAE\n",
    "from dataloader_VAE import get_h5ad_data, get_dataloader, normalize, inverse_normalize\n",
    "from train_VAE import train_vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "\n",
    "data_list = get_h5ad_data('drosophila_scNODE2_2000genes_2489cells_11tps.h5ad')\n",
    "norm_data_list, scalers = normalize(data_list)\n",
    "\n",
    "\n",
    "# 训练集和测试集对应的下标\n",
    "all_index = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "train_index = [0, 1, 2, 3, 5, 7, 9, 10]\n",
    "test_index = [4, 6, 8]\n",
    "\n",
    "train_list = [norm_data_list[i] for i in train_index]\n",
    "test_list = [norm_data_list[i] for i in test_index]\n",
    "\n",
    "train_dataloader = get_dataloader(train_list, train_index, batch_size=64)\n",
    "test_dataloader = get_dataloader(test_list, test_index, batch_size=64)\n",
    "all_dataloader = get_dataloader(norm_data_list, all_index, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████| 20/20 [01:18<00:00,  3.94s/it, recon_loss=109.551,kl_loss=3.291]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "net = VAE().to(device)\n",
    "\n",
    "num_epoch = 20\n",
    "train_vae(net, all_dataloader, num_epoch, device=device)\n",
    "\n",
    "# 保存模型\n",
    "model_path = '/home/hanyuji/Results/VAE_result/vae_model_0603_DR_all.pt'\n",
    "torch.save(net.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "device = \"cuda:0\"\n",
    "net = VAE().to(device)\n",
    "model_path = '/home/hanyuji/Results/VAE_result/vae_model_0603_DR_all.pt'\n",
    "net.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备存放输出\n",
    "latent_list_mix=[]\n",
    "latent_dict = {}  # 12个数组 [], [], [], [], [], [], [], [], [], [], [], []\n",
    "recon_dict = {}  # 12个数组\n",
    "\n",
    "# {4: [], 6: [], 8: []}\n",
    "# for index in test_index:\n",
    "for index in all_index:\n",
    "    \n",
    "    latent_dict[index] = []\n",
    "    recon_dict[index] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "# for (x, y) in test_dataloader:\n",
    "for (x, y) in all_dataloader:\n",
    "    \n",
    "    x = x.float().to(device)\n",
    "    z, mu, var = net.encoder(x)\n",
    "    recon = net.decoder(z)\n",
    "    \n",
    "    z_np = z.detach().cpu().numpy()\n",
    "    y_np = y.detach().cpu().numpy()\n",
    "    recon_np = recon.detach().cpu().numpy()\n",
    "        \n",
    "    for (z_i,y_i) in zip(z_np,y_np):\n",
    "        latent_dict[y_i].append(z_i)        \n",
    "    for (recon_i,y_i) in zip(recon_np,y_np):\n",
    "        recon_dict[y_i].append(recon_i)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_list = []\n",
    "recon_list = []\n",
    "label_list = []\n",
    "for index, arr in latent_dict.items():\n",
    "    latent_list.append(np.asarray(arr))\n",
    "    for _ in arr:\n",
    "        label_list.append(index)\n",
    "    \n",
    "for index, arr in recon_dict.items():\n",
    "    recon_list.append(np.asarray(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# 保存这些数组到一个文件\n",
    "\n",
    "file_name = 'DR_latent_50.pkl'\n",
    "with open('/home/hanyuji/Results/VAE_result/'+file_name, 'wb') as f:\n",
    "    pickle.dump(latent_list, f)\n",
    "\n",
    "# # 从文件加载这些数组\n",
    "# with open('array_list.pkl', 'rb') as f:\n",
    "#     loaded_array_list = pickle.load(f)\n",
    "\n",
    "# # 验证加载的数组与原始数组是否相同\n",
    "# for original, loaded in zip(latent_list, loaded_array_list):\n",
    "#     print(np.array_equal(original, loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DYffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
