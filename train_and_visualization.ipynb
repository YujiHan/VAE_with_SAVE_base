{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import scanpy as sc\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from model_VAE import VAE\n",
    "from dataloader_VAE import get_h5ad_data, get_dataloader, normalize, inverse_normalize\n",
    "from train_VAE import train_vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "\n",
    "data_list = get_h5ad_data()\n",
    "norm_data_list, scalers = normalize(data_list)\n",
    "dataloader = get_dataloader(norm_data_list, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████| 20/20 [00:40<00:00,  2.02s/it, recon_loss=249.770,kl_loss=5.346]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "net = VAE().to(device)\n",
    "\n",
    "num_epoch = 20\n",
    "epoch_loss = train_vae(net, dataloader, num_epoch, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_list_mix=[]\n",
    "latent_dict = [[], [], [], [], [], [], [], [], [], [], [], []]  # 12个数组\n",
    "recon_dict = [[], [], [], [], [], [], [], [], [], [], [], []]  # 12个数组\n",
    "\n",
    "for i, (x, y) in enumerate(dataloader):\n",
    "    x = x.float().to(device)\n",
    "    z, mu, var = net.encoder(x)\n",
    "    recon = net.decoder(z)\n",
    "    \n",
    "    z_np = z.detach().cpu().numpy()\n",
    "    y_np = y.detach().cpu().numpy()\n",
    "    recon_np = recon.detach().cpu().numpy()\n",
    "        \n",
    "    for (z_i,y_i) in zip(z_np,y_np):\n",
    "        latent_dict[y_i].append(z_i)        \n",
    "    for (recon_i,y_i) in zip(recon_np,y_np):\n",
    "        recon_dict[y_i].append(recon_i)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "latent_list = []\n",
    "recon_list = []\n",
    "label_list = []\n",
    "for index, arr in enumerate(latent_dict):\n",
    "    latent_list.append(np.asarray(arr))\n",
    "    for _ in arr:\n",
    "        label_list.append(index)\n",
    "    \n",
    "for arr in recon_dict:\n",
    "    recon_list.append(np.asarray(arr))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311, 2000)---(311, 50)\n",
      "(200, 2000)---(200, 50)\n",
      "(1158, 2000)---(1158, 50)\n",
      "(1467, 2000)---(1467, 50)\n",
      "(5716, 2000)---(5716, 50)\n",
      "(1026, 2000)---(1026, 50)\n",
      "(4101, 2000)---(4101, 50)\n",
      "(6178, 2000)---(6178, 50)\n",
      "(5442, 2000)---(5442, 50)\n",
      "(7114, 2000)---(7114, 50)\n",
      "(1614, 2000)---(1614, 50)\n",
      "(4404, 2000)---(4404, 50)\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(data_list,latent_list):\n",
    "    print(f'{i.shape}---{j.shape}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_array = np.concatenate(latent_list, axis=0)\n",
    "recon_array = np.concatenate(recon_list, axis=0)\n",
    "labels_array = label_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from umap.umap_ import UMAP\n",
    "# from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "from cuml import PCA, UMAP\n",
    "import cupy as cp\n",
    "\n",
    "device = cp.cuda.Device(0)\n",
    "device.use()\n",
    "\n",
    "def linearSegmentCMap(num_colors, cmap_name=\"plasma\"):\n",
    "    '''Construct colormap for linearly segmented colors.'''\n",
    "    cm = plt.get_cmap(cmap_name)\n",
    "    color_list = [cm(i//3*3.0/num_colors) for i in range(num_colors)]\n",
    "    return color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "pca_pcs = 5\n",
    "n_neighbors = 200\n",
    "min_dist = 0.8\n",
    "\n",
    "\n",
    "# 构建UMAP模型\n",
    "umap_model = UMAP(n_components=2, n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "umap_latent_data = umap_model.fit_transform(latent_array)\n",
    "\n",
    "\n",
    "# 构建PCA和UMAP模型\n",
    "pca_model_2 = PCA(n_components=pca_pcs, svd_solver=\"auto\")\n",
    "umap_model_2 = UMAP(n_components=2, n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "umap_recon_data = umap_model_2.fit_transform(pca_model_2.fit_transform(recon_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "'''Plot predictions at all timepoints.'''\n",
    "unique_tps = np.unique(labels_array).astype(int).tolist()\n",
    "n_tps = len(unique_tps)\n",
    "color_list = linearSegmentCMap(n_tps, cmap_name=\"plasma\")\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.set_title(\"Traj Data\", fontsize=15)\n",
    "for i, t in enumerate(unique_tps):\n",
    "    true_t_idx = np.where(labels_array == t)[0]\n",
    "    ax1.scatter(\n",
    "        umap_latent_data[true_t_idx, 0],\n",
    "        umap_latent_data[true_t_idx, 1],\n",
    "        label=t,\n",
    "        color=color_list[i],\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax2.scatter(\n",
    "        umap_recon_data[true_t_idx, 0],\n",
    "        umap_recon_data[true_t_idx, 1],\n",
    "        label=t,\n",
    "        color=color_list[i],\n",
    "        s=5,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "ax2.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DYffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
